{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,inspect\n",
    "current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.insert(0, parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import MinMaxScaler, PowerTransformer, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "import pickle\n",
    "\n",
    "from common.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureSelector( BaseEstimator, TransformerMixin ):\n",
    "    '''Selects list of features for transformation pipeline''' \n",
    "    def __init__( self, feature_type ):\n",
    "        self.feature_type = feature_type \n",
    "    \n",
    "    #Return self nothing else to do here    \n",
    "    def fit( self, X, y = None):\n",
    "        return self \n",
    "    \n",
    "    #Method that describes what we need this transformer to do\n",
    "    def transform( self, X, y = None):\n",
    "        print(f\"Transforming {self.feature_type} features.\")\n",
    "        if self.feature_type == 'numerical':\n",
    "            return X.select_dtypes(exclude='object')\n",
    "        if self.feature_type == 'categorical':\n",
    "            return X.select_dtypes(include='object')\n",
    "        return X\n",
    "\n",
    "\n",
    "class GeoRegionTransformer( BaseEstimator, TransformerMixin ):\n",
    "    def __init__(self):\n",
    "        from os import path\n",
    "        # basepath = path.dirname(__file__)\n",
    "        basepath = current_dir\n",
    "        clusterer_filepath = path.abspath(path.join(basepath, \"..\", \"common\", \"assets\", \"latlong_custerer_6.pkl\"))\n",
    "        self.lat_long_clusterer = None\n",
    "        with open(clusterer_filepath, 'rb') as f:\n",
    "            self.lat_long_clusterer = pickle.load(f)\n",
    "    \n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y = None):\n",
    "        # Cluster Lat and Long to Geo_Region (6 clusters)\n",
    "        X = identify_geo_region(X, self.lat_long_clusterer)\n",
    "        X = X.drop(['Lat', 'Long', 'State', 'District'], axis=1)\n",
    "        print('Clustered Lat-Long to Geo Region.')\n",
    "        return X\n",
    "\n",
    "\n",
    "class CropEncoder( BaseEstimator, TransformerMixin ):\n",
    "    def __init__(self):\n",
    "        # Weight of Evidence for Crop\n",
    "        self.woe = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.woe = crop_woe(pd.concat([X, y], axis=1), str(y.columns[0]), print_iv=False)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y = None):\n",
    "        # Encode Crop feature with WoE\n",
    "        X['Crop'] = X['Crop'].apply(lambda x: self.woe[x])\n",
    "        print('Encoded Crop using WoE.')\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CropDataProcessor():\n",
    "    \n",
    "    def __init__(self, data, excluded_features = [], has_yield_column = False):\n",
    "        \n",
    "        self.data = data.copy()\n",
    "        \n",
    "        self.excluded_features = excluded_features\n",
    "        \n",
    "        self.preprocessed = False\n",
    "        \n",
    "        if has_yield_column == False:\n",
    "            # Create column - Yield = Production / Area\n",
    "            self.data['Yield'] = (self.data['Production'] / self.data['Area']) + 1\n",
    "            self.data = self.data.drop(['Production', 'Area'], axis=1)\n",
    "        \n",
    "        self.target_transformer = PowerTransformer(method='box-cox', standardize=False)\n",
    "        \n",
    "        if len(excluded_features) > 0:\n",
    "            self.data = self.data.drop(excluded_features, axis=1)\n",
    "        \n",
    "        num_scaler_pipeline = Pipeline(steps = [\n",
    "            ('num-selector', FeatureSelector('numerical')),\n",
    "            ('minmax-scaler', MinMaxScaler(feature_range=(1, 2)))\n",
    "        ])\n",
    "        \n",
    "        cat_encoder_pipeline = Pipeline(steps = [\n",
    "            ('cat-selector', FeatureSelector('categorical')),\n",
    "            ('onehot-encoder', OneHotEncoder(sparse=False))\n",
    "        ])\n",
    "        \n",
    "        feature_transformers = FeatureUnion(transformer_list= [\n",
    "            ('num-scaler-pipeline', num_scaler_pipeline),\n",
    "            ('cat-encoder-pipeline', cat_encoder_pipeline)\n",
    "        ])\n",
    "        \n",
    "        self.feature_pipeline = Pipeline(steps=[\n",
    "            ('geo-region-transformer', GeoRegionTransformer()),\n",
    "            ('crop-woe-encoder', CropEncoder()),\n",
    "            ('feature-transformers', feature_transformers)\n",
    "        ])\n",
    "        \n",
    "        self.X = self.data.drop('Yield', axis=1)\n",
    "        self.y = self.data[['Yield']]\n",
    "        \n",
    "    def process_to_train(self):\n",
    "        # Normalize distribution of target\n",
    "        self.y = pd.DataFrame(self.target_transformer.fit_transform(self.y), columns=['Yield'])\n",
    "        self.X = self.feature_pipeline.fit_transform(self.X, self.y)\n",
    "        self.preprocessed = True\n",
    "        \n",
    "    def process_to_predict(self, features):\n",
    "        if len(self.excluded_features) > 0:\n",
    "            features = features.drop(self.excluded_features, axis=1)\n",
    "        return self.feature_pipeline.transform(features)\n",
    "        \n",
    "    def get_training_data(self):\n",
    "        if self.preprocessed == False:\n",
    "            print(\"Warning 1: Features are not processed yet.\")\n",
    "            print(\"Warning 2: Distribution of Yield may not be normal.\")\n",
    "        return self.X, self.y.values.flatten()\n",
    "        \n",
    "#     def train(self, model):\n",
    "#         if self.preprocessed == True:\n",
    "#             print(\"Training...\")\n",
    "#         else:\n",
    "#             print(\"Kindly preprocess the features (using method preprocess()) before training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('../data/Crop_Data__train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_data_processor = CropDataProcessor(test_df, excluded_features=['Dew_Frost_Point', 'Year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Features are not processed yet.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(164986, 21)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crop_data_processor.get_training_features().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Distribution of Yield may not be normal.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Yield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.342105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.556391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.816794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.025014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.439155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164981</th>\n",
       "      <td>1.921368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164982</th>\n",
       "      <td>60.092007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164983</th>\n",
       "      <td>5.964238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164984</th>\n",
       "      <td>2.217391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164985</th>\n",
       "      <td>3.981013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>164986 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Yield\n",
       "0        1.342105\n",
       "1        1.556391\n",
       "2        1.816794\n",
       "3        1.025014\n",
       "4        7.439155\n",
       "...           ...\n",
       "164981   1.921368\n",
       "164982  60.092007\n",
       "164983   5.964238\n",
       "164984   2.217391\n",
       "164985   3.981013\n",
       "\n",
       "[164986 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crop_data_processor.get_yield()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustered Lat-Long to Geo Region.\n",
      "Encoded Crop using WoE.\n",
      "Transforming numerical features.\n",
      "Transforming categorical features.\n"
     ]
    }
   ],
   "source": [
    "crop_data_processor.process_to_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
